## Default values for Vector
## See Vector helm documentation to learn more:
## https://vector.dev/docs/setup/installation/package-managers/helm/

# role -- Role for this Vector (possible values: Agent, Aggregator, Stateless-Aggregator)
## Ref: https://vector.dev/docs/setup/deployment/roles/
## Each role is created with the following workloads:
## Agent - DaemonSet
## Aggregator - StatefulSet
## Stateless-Aggregator - Deployment
role: "Aggregator"

# rollWorkload -- Add a checksum of the generated ConfigMap to workload annotations
rollWorkload: true

## Define the Vector image to use
image:
  # image.repository -- Override default registry + name for Vector
  repository: timberio/vector
  # image.pullPolicy -- Vector image pullPolicy
  pullPolicy: IfNotPresent
  # image.pullSecrets -- Agent repository pullSecret (ex: specify docker registry credentials)
  ## Ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  pullSecrets: []
  # image.tag -- Vector image tag to use
  # @default -- Chart's appVersion
  tag: ""

# replicas -- Set the number of Pods to create
## Valid for Aggregator and Stateless-Aggregator
replicas: 1

# podManagementPolicy -- Specify the podManagementPolicy for the Aggregator role
## Valid for Aggregator role
podManagementPolicy: OrderedReady

## Create a Secret resource for Vector to use
secrets:
  # secrets.generic -- Each Key/Value will be added to the Secret's data key
  ## Values should be entered base64 encoded (examples below are "REPLACE_ME" encoded)
  ## NOTE: Don't commit unencrypted secrets to git!
  generic: {}
    # awsAccessKeyId: "UkVQTEFDRV9NRQo="
    # awsSecretAccessKey: "UkVQTEFDRV9NRQo="

## Configure a HorizontalPodAutoscaler for Vector
## Valid for Stateless-Aggregator role
autoscaling:
  # autoscaling.enabled -- Enabled autoscaling for the Stateless-Aggregator
  enabled: false
  # autoscaling.minReplicas -- Minimum replicas for Vector's HPA
  minReplicas: 1
  # autoscaling.maxReplicas -- Maximum replicas for Vector's HPA
  maxReplicas: 10
  # autoscaling.targetCPUUtilizationPercentage -- Target CPU utilization for Vector's HPA
  targetCPUUtilizationPercentage: 80
  # autoscaling.targetMemoryUtilizationPercentage -- (int) Target memory utilization for Vector's HPA
  targetMemoryUtilizationPercentage:
  # autoscaling.customMetric -- Target a custom metric
  customMetric: {}
    #  - type: Pods
    #    pods:
    #      metric:
    #        name: utilization
    #      target:
    #        type: AverageValue
    #        averageValue: 95

rbac:
  # rbac.create -- If true, create and use RBAC resources
  create: true

serviceAccount:
  # serviceAccount.create -- If true, create ServiceAccount
  create: true
  # serviceAccount.annotations -- Annotations to add to the Vector ServiceAccount
  annotations: {}
  # serviceAccount.name -- The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the fullname template
  name:
  # serviceAccount.automountToken -- Automount API credentials for the Vector ServiceAccount
  automountToken: true

# podAnnotations -- Set annotations on Vector Pods
podAnnotations: {}

# podLabels -- Set labels on Vector Pods
podLabels: {}

# podPriorityClassName -- Set the priorityClassName on Vector Pods
podPriorityClassName: ""

# podSecurityContext -- Allows you to overwrite the default PodSecurityContext for Vector
podSecurityContext: {}

# securityContext -- Specify securityContext on Vector containers
securityContext: {}

# args -- Override Vector's default arguments
args:
  - --config-dir
  - "/etc/vector/"

# env -- Set environment variables in Vector containers
env: []
  # - name: AWS_ACCESS_KEY_ID
  #   valueFrom:
  #     secretKeyRef:
  #       name: vector-aggregator
  #       key: awsAcessKeyId

# resources -- Set Vector resource requests and limits.
resources: {}
  # requests:
  #   cpu: 200m
  #   memory: 256Mi
  # limits:
  #   cpu: 200m
  #   memory: 256Mi

# updateStrategy -- Customize the updateStrategy used to replace Vector Pods
## Also used for the DeploymentStrategy for Stateless-Aggregators
## Valid options are used depending on the chosen role
## Agent (DaemonSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/#DaemonSetSpec)
## Aggregator (StatefulSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/stateful-set-v1/#StatefulSetSpec
## Stateless-Aggregator (DeploymentStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/
updateStrategy: {}
#   type: RollingUpdate
#   rollingUpdate:
#     maxUnavailable: 1

# terminationGracePeriodSeconds -- Override Vector's terminationGracePeriodSeconds
terminationGracePeriodSeconds: 60

# nodeSelector -- Allow Vector to be scheduled on selected nodes
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
## Ref: https://kubernetes.io/docs/user-guide/node-selection/
nodeSelector: {}

# tolerations -- Allow Vector to schedule on tainted nodes
tolerations: []

# affinity -- Allow Vector to schedule using affinity rules
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

## Configuration for Vector's Service
service:
  # service.enabled -- If true, create and use a Service resource
  enabled: true
  # service.type -- Set type of Vector's Service
  type: "ClusterIP"
  # service.annotations -- Set annotations on Vector's Service
  annotations: {}
  # service.ports -- Override automated generation of Service ports
  ports: []

# existingConfigMap -- Use existing ConfigMap for Vector's configuration instead of creating a new one
## If set, this parameter takes precedence over customConfig and the chart's default configs
existingConfigMap: ""

# customConfig -- Override Vector's default configs, if used **all** options need to be specified
## This section supports using helm templates to populate dynamic values
## Ref: https://vector.dev/docs/reference/configuration/
customConfig: {}

## Configuration for Vector's data persistence
persistence:
  # persistence.enabled -- If true, create and use PersistentVolumeClaims
  enabled: false
  # persistence.existingClaim -- Name of an existing PersistentVolumeClaim to use
  ## Valid for Aggregator role
  existingClaim: ""
  # persistence.storageClassName -- Specifies the storageClassName for PersistentVolumeClaims
  ## Valid for Aggregator role
  # storageClassName: default

  # persistence.accessModes -- Specifies the accessModes for PersistentVolumeClaims
  ## Valid for Aggregator role
  accessModes:
    - ReadWriteOnce
  # persistence.size -- Specifies the size of PersistentVolumeClaims
  ## Valid for Aggregator role
  size: 10Gi
  # persistence.finalizers -- Specifies the finalizers of PersistentVolumeClaims
  ## Valid for Aggregator role
  finalizers:
    - kubernetes.io/pvc-protection
  # persistence.selectors -- Specifies the selectors for PersistentVolumeClaims
  ## Valid for Aggregator role
  selectors: {}

  hostPath:
    # persistence.hostPath.path -- Override path used for hostPath persistence
    ## Valid for Agent role, persistence always used for Agent role
    path: "/var/lib/vector"

# dnsPolicy -- Specify DNS policy for Vector Pods
## Ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy
dnsPolicy: ClusterFirst

# dnsConfig -- Specify DNS configuration options for Vector Pods
## Ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config
dnsConfig: {}
  # nameservers:
  #   - 1.2.3.4
  # searches:
  #   - ns1.svc.cluster-domain.example
  #   - my.dns.search.suffix
  # options:
  #   - name: ndots
  #     value: "2"
  #   - name: edns0

# livenessProbe -- Override default liveness probe settings
## Requires Vector's API to be enabled
livenessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

# readinessProbe -- Override default readiness probe settings, if customConfig is used require customConfig.api.enabled true
## Requires Vector's API to be enabled
readinessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

## Configure a PodMonitor for Vector
## Requires the PodMonitor CRD to be installed
podMonitor:
  # podMonitor.enabled -- If true, create a PodMonitor for Vector
  enabled: false
  # podMonitor.jobLabel -- Override the label to retrieve the job name from
  jobLabel: app.kubernetes.io/name
  # podMonitor.port -- Override the port to scrape
  port: prom-exporter
  # podMonitor.path -- Override the path to scrape
  path: /metrics
  # podMonitor.relabelings -- RelabelConfigs to apply to samples before scraping
  ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
  relabelings: []
  # podMonitor.metricRelabelings -- MetricRelabelConfigs to apply to samples before ingestion
  ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
  metricRelabelings: []

## Optional built-in HAProxy load balancer
haproxy:
  # haproxy.enabled -- If true, create a HAProxy load balancer
  enabled: false

  ## Define the HAProxy image to use
  image:
    # haproxy.image.repository -- Override default registry + name for HAProxy
    repository: haproxytech/haproxy-alpine
    # haproxy.image.pullPolicy -- HAProxy image pullPolicy
    pullPolicy: IfNotPresent
    # haproxy.image.pullSecrets -- HAProxy repository pullSecret (ex: specify docker registry credentials)
    ## Ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
    pullSecrets: []
    # haproxy.image.tag -- HAProxy image tag to use
    tag: "2.4.4"

  # haproxy.rollWorkload -- Add a checksum of the generated ConfigMap to the HAProxy Deployment
  rollWorkload: true

  # haproxy.replicas -- Set the number of HAProxy Pods to create
  replicas: 1

  serviceAccount:
    # haproxy.serviceAccount.create -- If true, create a HAProxy ServiceAccount
    create: true
    # haproxy.serviceAccount.annotations -- Annotations to add to the HAProxy ServiceAccount
    annotations: {}
    # haproxy.serviceAccount.name -- The name of the HAProxy ServiceAccount to use.
    ## If not set and create is true, a name is generated using the fullname template
    name:
    # haproxy.serviceAccount.automountToken -- Automount API credentials for the HAProxy ServiceAccount
    automountToken: true

  # haproxy.terminationGracePeriodSeconds -- Override HAProxy's terminationGracePeriodSeconds
  terminationGracePeriodSeconds: 60

  # haproxy.podAnnotations -- Set annotations on HAProxy Pods
  podAnnotations: {}

  # haproxy.podLabels -- Set labels on HAProxy Pods
  podLabels: {}

  # haproxy.podPriorityClassName -- Set the priorityClassName on HAProxy Pods
  podPriorityClassName: ""

  # haproxy.podSecurityContext -- Allows you to overwrite the default PodSecurityContext for HAProxy
  podSecurityContext: {}
    # fsGroup: 2000

  # haproxy.securityContext -- Specify securityContext on HAProxy containers
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  ## HAProxy's Service configuration
  service:
    # haproxy.service.type -- Set type of HAProxy's Service
    type: ClusterIP

  # haproxy.existingConfigMap -- Use existing ConfigMap for HAProxy's configuration instead of creating a new one
  ## If set, this parameter takes precedence over customConfig and the chart's default configs
  existingConfigMap: ""

  # haproxy.customConfig -- Override HAProxy's default configs, if used **all** options need to be specified
  ## The chart will parse sources and sinks from customConfig to generate HAProxy config, this generated config
  ## can be overwritten with haproxy.customConfig
  ## This section supports using helm templates to populate dynamic values
  customConfig: ""

  ## Configure a HorizontalPodAutoscaler for HAProxy
  autoscaling:
    # haproxy.autoscaling.enabled -- Enabled autoscaling for HAProxy
    enabled: false
    # haproxy.autoscaling.minReplicas -- Minimum replicas for HAProxy's HPA
    minReplicas: 1
    # haproxy.autoscaling.maxReplicas -- Maximum replicas for HAProxy's HPA
    maxReplicas: 10
    # haproxy.autoscaling.targetCPUUtilizationPercentage -- Target CPU utilization for HAProxy's HPA
    targetCPUUtilizationPercentage: 80
    # haproxy.autoscaling.targetMemoryUtilizationPercentage -- (int) Target memory utilization for HAProxy's HPA
    targetMemoryUtilizationPercentage:
    # haproxy.autoscaling.customMetric -- Target a custom metric
    customMetric: {}
      #  - type: Pods
      #    pods:
      #      metric:
      #        name: utilization
      #      target:
      #        type: AverageValue
      #        averageValue: 95

  # haproxy.resources -- Set HAProxy resource requests and limits.
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # haproxy.nodeSelector -- Allow HAProxy to be scheduled on selected nodes
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # haproxy.tolerations -- Allow HAProxy to schedule on tainted nodes
  tolerations: []

  # haproxy.affinity -- Allow HAProxy to schedule using affinity rules
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
