## Default values for Vector
## See Vector helm documentation to learn more:
## https://vector.dev/docs/setup/installation/package-managers/helm/

# role -- Role for this deployment (possible values: Agent, Aggregator, Stateless-Aggregator)
## Ref: https://vector.dev/docs/setup/deployment/roles/
## Each role is created with the following workloads:
## Agent - DaemonSet
## Aggregator - StatefulSet
## Stateless-Aggregator - Deployment
role: "Aggregator"

image:
  repository: timberio/vector
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion
  tag: ""

# replicas -- Set the number of pods to create
## Valid for Aggregator and Stateless-Aggregator
replicas: 1

autoscaling:
  # autoscaling.enabled -- Enabled autoscaling for the Stateless-Aggregator
  enabled: false
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
  customMetric: {}
    #  - type: Pods
    #    pods:
    #      metric:
    #        name: utilization
    #      target:
    #        type: AverageValue
    #        averageValue: 95

rbac:
  # rbac.create -- If true, create and use RBAC resources
  create: true

serviceAccount:
  # serviceAccount.create -- If true, create ServiceAccount
  create: true

  # serviceAccount.name -- The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the fullname template
  name:

# podSecurityContext -- Allows you to overwrite the default PodSecurityContext on the Daemonset or StatefulSet
podSecurityContext: {}

# securityContext -- Specify securityContext on the vector container
securityContext: {}

# resources -- Vector resource requests and limits.
resources: {}
  # requests:
  #   cpu: 200m
  #   memory: 256Mi
  # limits:
  #   cpu: 200m
  #   memory: 256Mi

# updateStrategy -- Customize the updateStrategy used to replace Vector Pods
## Also used for the DeploymentStrategy for Stateless-Aggregators
## Valid options are used depending on the chosen role
## Agent (DaemonSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/#DaemonSetSpec)
## Aggregator (StatefulSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/stateful-set-v1/#StatefulSetSpec
## Stateless-Aggregator (DeploymentStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/
updateStrategy: {}
#   type: RollingUpdate
#   rollingUpdate:
#     maxUnavailable: 1

# nodeSelector -- Allow Vector to be scheduled on selected nodes
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
## Ref: https://kubernetes.io/docs/user-guide/node-selection/
nodeSelector: {}

# tolerations -- Allow Vector to schedule on tainted nodes (requires Kubernetes >= 1.6)
tolerations: []

# affinity -- Allow Vector to schedule using affinity rules
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

## Configuration for Vector's Service
service:
  # service.enabled -- If true, create and use a Service resource
  enabled: true

# customConfig -- Override Vector's default configs, if used **all** options need to be specified
## Ref: https://vector.dev/docs/reference/configuration/
customConfig: {}

## Configuration for Vector's data persistence
persistence:
  # persistence.enabled -- If true, create and use PersistentVolumeClaims
  enabled: false
  # persistence.existingClaim -- Name of an existing PersistentVolumeClaim to use
  ## Valid for Aggregator role
  existingClaim: ""
  # persistence.storageClassName -- Specifies the storageClassName for PersistentVolumeClaims
  ## Valid for Aggregator role
  # storageClassName: default

  # persistence.accessModes -- Specifies the accessModes for PersistentVolumeClaims
  ## Valid for Aggregator role
  accessModes:
    - ReadWriteOnce
  # persistence.size -- Specifies the size of PersistentVolumeClaims
  ## Valid for Aggregator role
  size: 10Gi
  # persistence.finalizers -- Specifies the finalizers of PersistentVolumeClaims
  ## Valid for Aggregator role
  finalizers:
    - kubernetes.io/pvc-protection
  # persistence.selectors -- Specifies the selectors for PersistentVolumeClaims
  ## Valid for Aggregator role
  selectors: {}

  hostPath:
    # persistence.hostPath.path -- Override path used for hostPath persistence
    ## Valid for Agent role
    path: "/var/lib/vector"

# livenessProbe -- Override default liveness probe settings
## Requires Vector's API to be enabled
livenessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

# readinessProbe -- Override default readiness probe settings, if customConfig is used require customConfig.api.enabled true
## Requires Vector's API to be enabled
readinessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

## Optional built-in HAProxy load balancer
haproxy:
  # haproxy.enabled -- If true, create a HAProxy load balancer
  enabled: false

  image:
    repository: haproxytech/haproxy-alpine
    pullPolicy: IfNotPresent
    tag: "2.4.4"

  imagePullSecrets: []
  nameOverride: ""
  fullnameOverride: ""

  # haproxy.replicas -- Set the number of pods to create
  replicas: 1

  serviceAccount:
    # haproxy.serviceAccount.create -- If true, create ServiceAccount
    create: true

    # haproxy.serviceAccount.name -- The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the fullname template
    name:

  terminationGracePeriodSeconds: 60

  podAnnotations: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    type: ClusterIP

  autoscaling:
    # haproxy.autoscaling.enabled -- Enabled autoscaling for the HAProxy load balancer
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80
    customMetric: {}
      #  - type: Pods
      #    pods:
      #      metric:
      #        name: utilization
      #      target:
      #        type: AverageValue
      #        averageValue: 95

  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}
